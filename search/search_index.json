{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction to Cloud Migration This tutorial is designed to show you with a concrete example how to perform a migration to the public cloud. In this tutorial, we will migrate a simple CRUD (Create, Read, Update, Delete) application progressively to the cloud, leveraging more and more on different managed services the further we go. Throughout the tutorial, the functionality of the application will not change, it will just become more reliable and less costly. This tutorial guides you through the following steps: Manually deploy an application on EC2 Instances here Automatically deploy an application on EC2 Instances here Make use of a managed database service here Containerize an application and use a container service here Use a managed runtime environment and make the application serverless here","title":"Introduction"},{"location":"#introduction-to-cloud-migration","text":"This tutorial is designed to show you with a concrete example how to perform a migration to the public cloud. In this tutorial, we will migrate a simple CRUD (Create, Read, Update, Delete) application progressively to the cloud, leveraging more and more on different managed services the further we go. Throughout the tutorial, the functionality of the application will not change, it will just become more reliable and less costly. This tutorial guides you through the following steps: Manually deploy an application on EC2 Instances here Automatically deploy an application on EC2 Instances here Make use of a managed database service here Containerize an application and use a container service here Use a managed runtime environment and make the application serverless here","title":"Introduction to Cloud Migration"},{"location":"cicd_artifacts/","text":"Continuous Integration and Delivery In an enterprise context, it's normally not one person doing the build, test and deploy steps for an application. You rather rely on an automated system which gives you clear visibility on who did when which change. In this lab, we will not build a very advanced CI/CD system as you have a dedicated course for that, but we will try to focus on a MVP (minimum viable product) configuration. At the end of this lab, every commit to the master branch of your repository should result in a build process to start. Step-by-Step instructions Fork this repository. It contains the application source code (in src/) the infrastructure source code (in docs/files/) Create a programmatic IAM user in AWS. Give EC2FullAccess and CloudFormationFullAccess managed policy to this user. Generate an Access Key ID and Secret Access Key bundle. Add the following secrets to your previously forked Github repository: AWS_ACCESS_KEY_ID : from the previously created bundle. AWS_SECRET_ACCESS_KEY : from the previously created bundle. DBName : choose freely DBPassword : choose freely DBRootPassword : choose freely DBUser : choose freely KeyName : the name of the keypair you created in the previous exercise Create an S3 bucket that will be used to store your artifacts. Uncheck the box asking you to forbid making the bucket public. Add a bucket policy allowing the previously created user to upload artifacts and change an objects ACL (Access Control List).","title":"Deploy through a CI/CD Pipeline"},{"location":"cicd_artifacts/#continuous-integration-and-delivery","text":"In an enterprise context, it's normally not one person doing the build, test and deploy steps for an application. You rather rely on an automated system which gives you clear visibility on who did when which change. In this lab, we will not build a very advanced CI/CD system as you have a dedicated course for that, but we will try to focus on a MVP (minimum viable product) configuration. At the end of this lab, every commit to the master branch of your repository should result in a build process to start.","title":"Continuous Integration and Delivery"},{"location":"cicd_artifacts/#step-by-step-instructions","text":"Fork this repository. It contains the application source code (in src/) the infrastructure source code (in docs/files/) Create a programmatic IAM user in AWS. Give EC2FullAccess and CloudFormationFullAccess managed policy to this user. Generate an Access Key ID and Secret Access Key bundle. Add the following secrets to your previously forked Github repository: AWS_ACCESS_KEY_ID : from the previously created bundle. AWS_SECRET_ACCESS_KEY : from the previously created bundle. DBName : choose freely DBPassword : choose freely DBRootPassword : choose freely DBUser : choose freely KeyName : the name of the keypair you created in the previous exercise Create an S3 bucket that will be used to store your artifacts. Uncheck the box asking you to forbid making the bucket public. Add a bucket policy allowing the previously created user to upload artifacts and change an objects ACL (Access Control List).","title":"Step-by-Step instructions"},{"location":"docker/","text":"Containerisation In this tutorial, we would like to make our application easily transferable between different cloud providers. As you have learned throughout the course, containerisation is a good way to achieve that goal. In this tutorial, we will add a Dockerfile to our repository and push it to AWS ECR. Once this is done, we will address the deployment of container through ECS, the Container service of AWS. There is already a Dockerfile in the /src directory of this repository. You can use it to build the Docker image on your local workstation. For this tutorial, you'll have to use the AWS Documentation and find out the following things: How to log in with the AWS CLI to AWS ECR How to push a Docker image to AWS ECR How to deploy a Docker image to AWS ECS Follow-up exercise Check the pipeline in the .github/workflows/docker.yaml . Make the pipeline work so that a new push to your Github repository results in a new Image Build + Push + Deployment.","title":"Port your application to Docker"},{"location":"docker/#containerisation","text":"In this tutorial, we would like to make our application easily transferable between different cloud providers. As you have learned throughout the course, containerisation is a good way to achieve that goal. In this tutorial, we will add a Dockerfile to our repository and push it to AWS ECR. Once this is done, we will address the deployment of container through ECS, the Container service of AWS. There is already a Dockerfile in the /src directory of this repository. You can use it to build the Docker image on your local workstation. For this tutorial, you'll have to use the AWS Documentation and find out the following things: How to log in with the AWS CLI to AWS ECR How to push a Docker image to AWS ECR How to deploy a Docker image to AWS ECS","title":"Containerisation"},{"location":"docker/#follow-up-exercise","text":"Check the pipeline in the .github/workflows/docker.yaml . Make the pipeline work so that a new push to your Github repository results in a new Image Build + Push + Deployment.","title":"Follow-up exercise"},{"location":"iaas/","text":"Infrastructure as a Service In this first exercise, we are building an application consisting out of two components: A web server that is containg a so called CRUD application (Create, Read, Update, Delete) A database server that is hosting the applications data Step-by-Step instructions Go to the AWS Console and deploy an EC2 Instance through the EC2 Console. This EC2 instance will act as your database. When going through the wizard, take care of the following things: Choose the latest \"Amazon Linux 2\" AMI (Amazon Machine Image as image) Choose \"t2.micro\" as instance type In the security group screen, allow connections on port 3306 (MySQL) and 22 (SSH) from anywhere When launching the instance, create a new key pair do not lose the file that is downloaded after creating the keypair, you need it to connect to your EC2 instance After your EC2 instance is launched, connect to your instance with SSH: Go in your terminal to the folder with the previously downloaded key pair Connect with SSH like follows: ssh - i < your - key - pair . pem > ec2 - user @< public - ip - of - your - ec2 - instance > Install MySQL on this EC2 instance: yum install - y mysql mariadb - server Run the following statement to create your database schema: wget https : // 3 r1 . co / cloud - migration / files / database . sql mysql - u root < database . sql With this, you have successfully installed and configured your database. Now we move on the webserver installation. Go again to the AWS Console and deploy an EC2 Instance through the EC2 Console. This EC2 instance will act as your webserver. When going through the wizard, take care of the following things: Choose the latest \"Amazon Linux 2\" AMI (Amazon Machine Image as image) Choose \"t2.micro\" as instance type In the security group screen, allow connections on port 8080 (HTTP) and 22 (SSH) from anywhere When launching the instance, use your existing key pair. After your EC2 instance is launched, connect to your instance with SSH: Go in your terminal to the folder with the previously downloaded key pair Connect with SSH like follows: ssh - i < your - key - pair . pem > ec2 - user @< public - ip - of - your - ec2 - instance > Download and start the sample webserver application: wget https : // 3 r1co - github - artifacts . s3 . amazonaws . com / crud - app . tar . gz tar xzvf crud - app . tar . gz cd crud - app . / crud - app --dbHost <private-ip-of-your-database-instance> --dbName isen --dbUser isenuser --dbPass isen1234 In your browser go to http:// :8080 . You should see your application running. Congratulations, you have now deployed our first application based on VM Instances. Follow up exercise To get familiar with CloudFormation, there is a sample file available here . Deploy this file with CloudFormation. Currently, the cf-application.yaml is deploying a single EC2 Instance. Your task is now to transform the EC2 Resource into a Launch Configuration . Afterwards, assign this Launch Configuration to an Autoscaling Group . Next steps You can now move to the next chapter, where we will automate the deployment of our application.","title":"Infrastructure as a Service"},{"location":"iaas/#infrastructure-as-a-service","text":"In this first exercise, we are building an application consisting out of two components: A web server that is containg a so called CRUD application (Create, Read, Update, Delete) A database server that is hosting the applications data","title":"Infrastructure as a Service"},{"location":"iaas/#step-by-step-instructions","text":"Go to the AWS Console and deploy an EC2 Instance through the EC2 Console. This EC2 instance will act as your database. When going through the wizard, take care of the following things: Choose the latest \"Amazon Linux 2\" AMI (Amazon Machine Image as image) Choose \"t2.micro\" as instance type In the security group screen, allow connections on port 3306 (MySQL) and 22 (SSH) from anywhere When launching the instance, create a new key pair do not lose the file that is downloaded after creating the keypair, you need it to connect to your EC2 instance After your EC2 instance is launched, connect to your instance with SSH: Go in your terminal to the folder with the previously downloaded key pair Connect with SSH like follows: ssh - i < your - key - pair . pem > ec2 - user @< public - ip - of - your - ec2 - instance > Install MySQL on this EC2 instance: yum install - y mysql mariadb - server Run the following statement to create your database schema: wget https : // 3 r1 . co / cloud - migration / files / database . sql mysql - u root < database . sql With this, you have successfully installed and configured your database. Now we move on the webserver installation. Go again to the AWS Console and deploy an EC2 Instance through the EC2 Console. This EC2 instance will act as your webserver. When going through the wizard, take care of the following things: Choose the latest \"Amazon Linux 2\" AMI (Amazon Machine Image as image) Choose \"t2.micro\" as instance type In the security group screen, allow connections on port 8080 (HTTP) and 22 (SSH) from anywhere When launching the instance, use your existing key pair. After your EC2 instance is launched, connect to your instance with SSH: Go in your terminal to the folder with the previously downloaded key pair Connect with SSH like follows: ssh - i < your - key - pair . pem > ec2 - user @< public - ip - of - your - ec2 - instance > Download and start the sample webserver application: wget https : // 3 r1co - github - artifacts . s3 . amazonaws . com / crud - app . tar . gz tar xzvf crud - app . tar . gz cd crud - app . / crud - app --dbHost <private-ip-of-your-database-instance> --dbName isen --dbUser isenuser --dbPass isen1234 In your browser go to http:// :8080 . You should see your application running. Congratulations, you have now deployed our first application based on VM Instances.","title":"Step-by-Step instructions"},{"location":"iaas/#follow-up-exercise","text":"To get familiar with CloudFormation, there is a sample file available here . Deploy this file with CloudFormation. Currently, the cf-application.yaml is deploying a single EC2 Instance. Your task is now to transform the EC2 Resource into a Launch Configuration . Afterwards, assign this Launch Configuration to an Autoscaling Group .","title":"Follow up exercise"},{"location":"iaas/#next-steps","text":"You can now move to the next chapter, where we will automate the deployment of our application.","title":"Next steps"},{"location":"iaas_w_aurora/","text":"IaaS with Aurora You realized now that it's a difficult task to build a CloudFormation for Database. Also, the example that you deployed in the previous exercise is highly unsecure (as it's accessible from everywhere) and also not very reliable (as there is only one instance). Luckily, AWS provides a service called RDS (Relational Database Service). As part of RDS, there is a product called Aurora Serverless. It's a database that is completely compatible with MySQL and brings all the advantages of Serverless technology, means less resources to manage for you. In this exercise we deploy now Aurora through CloudFormation and change the configuration of our Webserver to use the new database. In a real-world use case you would for sure migrate your existing data, but let's skip that for now. Step-by-Step instructions Update the cf-all.yaml CloudFormation and add the cluster resource from here: cf-aurora.yaml . Remove the Database resource and the according DatabaseSecurityGroup in the cf-all.yaml , you don't need it anymore. Commit and push your infrastructure source code changes to Github. Congratulations, you have one EC2 instance less to manage! Also you get the following advantages: Transparent Scalability High availability Managed Backups You can now move to the next chapter, where we will see how we can make our application easier transferable.","title":"The first managed service, Aurora"},{"location":"iaas_w_aurora/#iaas-with-aurora","text":"You realized now that it's a difficult task to build a CloudFormation for Database. Also, the example that you deployed in the previous exercise is highly unsecure (as it's accessible from everywhere) and also not very reliable (as there is only one instance). Luckily, AWS provides a service called RDS (Relational Database Service). As part of RDS, there is a product called Aurora Serverless. It's a database that is completely compatible with MySQL and brings all the advantages of Serverless technology, means less resources to manage for you. In this exercise we deploy now Aurora through CloudFormation and change the configuration of our Webserver to use the new database. In a real-world use case you would for sure migrate your existing data, but let's skip that for now.","title":"IaaS with Aurora"},{"location":"iaas_w_aurora/#step-by-step-instructions","text":"Update the cf-all.yaml CloudFormation and add the cluster resource from here: cf-aurora.yaml . Remove the Database resource and the according DatabaseSecurityGroup in the cf-all.yaml , you don't need it anymore. Commit and push your infrastructure source code changes to Github. Congratulations, you have one EC2 instance less to manage! Also you get the following advantages: Transparent Scalability High availability Managed Backups You can now move to the next chapter, where we will see how we can make our application easier transferable.","title":"Step-by-Step instructions"},{"location":"lambda/","text":"All in with Serverless The ultimate goal of application refactoring is making it Serverless. The application in the /src directory is already compatible with AWS Lambda. You now have to find out how to: Compile a Golang application for AWS Lambda Package the application to be compatible with AWS Lambda (ZIP Format) Deploy the Lambda package Additionally, create an Application Load Balancer to routes traffic to your Lambda function. Follow-up exercise Create a Github Workflow that automatically builds, packages and deploys your Lambda Function.","title":"Port your application to Lambda"},{"location":"lambda/#all-in-with-serverless","text":"The ultimate goal of application refactoring is making it Serverless. The application in the /src directory is already compatible with AWS Lambda. You now have to find out how to: Compile a Golang application for AWS Lambda Package the application to be compatible with AWS Lambda (ZIP Format) Deploy the Lambda package Additionally, create an Application Load Balancer to routes traffic to your Lambda function.","title":"All in with Serverless"},{"location":"lambda/#follow-up-exercise","text":"Create a Github Workflow that automatically builds, packages and deploys your Lambda Function.","title":"Follow-up exercise"}]}